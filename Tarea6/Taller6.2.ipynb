{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Especialidad en Estadistica Aplicada \n",
        "## Tarea 6: Taller 6.2 - Redes Neuronales\n",
        "## Mateo Orozco Baldovino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TdGkXFUjYXn"
      },
      "source": [
        "# **Ejemplo de aplicación con Redes Neuronales para el dataset de Iris**\n",
        "\n",
        "**Descripción del dataset:**\n",
        "\n",
        "**Objetivo:** El dataset Iris es utilizado para problemas de clasificación. El objetivo es predecir la especie de una flor de iris (clasificación) basada en las medidas de sus características físicas.\n",
        "\n",
        "**Clases:** Hay tres clases (especies) de flores:\n",
        "\n",
        "*   Setosa\n",
        "*   Versicolor\n",
        "*   Virginica\n",
        "\n",
        "**Características:** El dataset contiene 150 observaciones, cada una con 4 características (medidas) que describen las flores:\n",
        "\n",
        "* Largo del sépalo (en cm)\n",
        "* Ancho del sépalo (en cm)\n",
        "* Largo del pétalo (en cm)\n",
        "* Ancho del pétalo (en cm)\n",
        "\n",
        "**Distribución de las clases:**\n",
        "\n",
        "* Cada clase tiene 50 ejemplos.\n",
        "* Las clases Setosa y Versicolor están perfectamente separadas linealmente, mientras que Versicolor y Virginica están algo superpuestas, lo que hace que la clasificación entre estas últimas dos sea más difícil."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Taller 6 - Parte 2**\n",
        "\n",
        "1. Efecto de los porcentajes de muestras de entrenamiento/prueba:\n",
        "\n",
        "* **Instrucción:** Entrena una red neuronal utilizando diferentes divisiones de datos para entrenamiento y prueba (por ejemplo, 70/30, 80/20, 90/10). Compara los resultados de precisión, matriz de confusión y el tiempo de entrenamiento.\n",
        "\n",
        "* **Preguntas:**\n",
        "- ¿Cómo afecta el tamaño del conjunto de entrenamiento a la precisión de la red neuronal?\n",
        "- ¿Qué relación observas entre el tamaño del conjunto de entrenamiento y el tiempo de cómputo?\n",
        "- ¿Cuál es la configuración que ofrece un mejor balance entre tiempo y precisión?\n",
        "\n",
        "2. Variación del número de capas y neuronas:\n",
        "\n",
        "* **Instrucción:** Realiza pruebas variando el número de capas ocultas y neuronas. Usa al menos tres configuraciones distintas (por ejemplo: (5,5), (10,10), (20,20)).\n",
        "\n",
        "* **Preguntas:**\n",
        "- ¿Cómo influye el número de capas ocultas y neuronas en la precisión del modelo?\n",
        "- ¿Qué configuración logra un mejor desempeño en términos de precisión y tiempo de cómputo?\n",
        "- ¿Cuál es el impacto del incremento en las neuronas en el tiempo de entrenamiento?\n",
        "\n",
        "3. Efecto de la función de activación:\n",
        "\n",
        "* **Instrucción:** Cambia la función de activación de la red neuronal. Prueba al menos tres funciones: relu, tanh, y logistic.\n",
        "\n",
        "* **Preguntas:**\n",
        "- ¿Cómo afecta la elección de la función de activación a los resultados de precisión y matriz de confusión?\n",
        "- ¿Qué función de activación logra un mejor tiempo de convergencia?\n",
        "- ¿Qué diferencias observas en el comportamiento de la red para cada función de activación en términos de curva de aprendizaje?\n",
        "\n",
        "4. Evaluación del tiempo de cómputo:\n",
        "\n",
        "* **Instrucción:** Mide el tiempo de cómputo total para cada una de las configuraciones anteriores (variando porcentajes de entrenamiento/prueba, capas, neuronas, y función de activación).\n",
        "\n",
        "* **Preguntas:**\n",
        "- ¿Qué parámetros de la red tienen un mayor impacto en el tiempo de cómputo?\n",
        "- ¿Cómo se puede mejorar el tiempo de ejecución sin perder demasiada precisión?\n",
        "- ¿Cuál sería el mejor enfoque para lograr un balance entre precisión y tiempo de cómputo?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalización de los datos\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# División del dataset en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear el modelo de red neuronal\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42, verbose=True)\n",
        "\n",
        "# Entrenar la red neuronal\n",
        "mlp.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Error final después del entrenamiento\n",
        "final_loss = mlp.loss_\n",
        "print(f\"Error final después del entrenamiento (loss): {final_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Configuración interna de la red neuronal\n",
        "print(\"\\nConfiguración de la red neuronal:\")\n",
        "print(f\"Número de capas: {mlp.n_layers_}\")\n",
        "print(f\"Neuronas por capa: {mlp.hidden_layer_sizes}\")\n",
        "print(f\"Funciones de activación: {mlp.activation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Curva de pérdida durante el entrenamiento\n",
        "plt.plot(mlp.loss_curve_)\n",
        "plt.title('Curva de épocas de entrenamiento (Pérdida)')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predicciones\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Matriz de confusión y overall accuracy\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "overall_accuracy = np.mean(y_test == y_pred)\n",
        "print(f\"Overall Accuracy (Red Neuronal): {overall_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report (Red Neuronal):\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Graficar la matriz de confusión\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
        "plt.xlabel('Predicciones')\n",
        "plt.ylabel('Valores Reales')\n",
        "plt.title('Matriz de Confusión (Red Neuronal)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dp4LYTnYjHJY",
        "outputId": "4f921de0-28ea-41f4-ceb8-d70e833c7dd9"
      },
      "outputs": [],
      "source": [
        "# Calcular y graficar ROC y AUC para cada clase\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "roc_auc = {}\n",
        "\n",
        "for i in range(3):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test, mlp.predict_proba(X_test)[:, i], pos_label=i)\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Graficar todas las ROC curves\n",
        "plt.figure()\n",
        "for i in range(3):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'ROC curve (Clase {i}) (area = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Tasa de Falsos Positivos')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "plt.title('Curva ROC (Red Neuronal)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Punto 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diferentes divisiones de datos\n",
        "splits = [(0.3, '70/30'), (0.2, '80/20'), (0.1, '90/10')]\n",
        "\n",
        "results = []\n",
        "\n",
        "for test_size, split_name in splits:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"DIVISIÓN: {split_name} (Train/Test)\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # División del dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=42)\n",
        "    \n",
        "    # Crear y entrenar el modelo\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42, verbose=False)\n",
        "    mlp.fit(X_train, y_train)\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # Predicciones\n",
        "    y_pred = mlp.predict(X_test)\n",
        "    \n",
        "    # Métricas\n",
        "    accuracy = np.mean(y_test == y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    \n",
        "    # Guardar resultados\n",
        "    results.append({\n",
        "        'split': split_name,\n",
        "        'accuracy': accuracy,\n",
        "        'conf_matrix': conf_matrix,\n",
        "        'training_time': training_time,\n",
        "        'train_size': len(X_train),\n",
        "        'test_size': len(X_test)\n",
        "    })\n",
        "    \n",
        "    # Imprimir resultados\n",
        "    print(f\"Tamaño conjunto entrenamiento: {len(X_train)}\")\n",
        "    print(f\"Tamaño conjunto prueba: {len(X_test)}\")\n",
        "    print(f\"Tiempo de entrenamiento: {training_time:.4f} segundos\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"\\nMatriz de Confusión:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "# Comparación final\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"RESUMEN COMPARATIVO\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"{'División':<10} {'Accuracy':<12} {'Tiempo (s)':<15} {'Train/Test'}\")\n",
        "print(\"-\" * 50)\n",
        "for r in results:\n",
        "    print(f\"{r['split']:<10} {r['accuracy']:<12.4f} {r['training_time']:<15.4f} {r['train_size']}/{r['test_size']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l33NbQLDkCgY"
      },
      "source": [
        "## 1. ¿Cómo afecta el tamaño del conjunto de entrenamiento a la precisión de la red neuronal?\n",
        "\n",
        "Observación: A mayor tamaño del conjunto de entrenamiento, mayor es la precisión del modelo.\n",
        "\n",
        "- 70/30 (105 entrenamiento): Accuracy = 1.0000 (100%)\n",
        "- 80/20 (120 entrenamiento): Accuracy = 0.9667 (96.67%)\n",
        "- 90/10 (135 entrenamiento): Accuracy = 0.9333 (93.33%)\n",
        "\n",
        "Análisis: En este caso específico se observa una relación inversa, la división 70/30 logró la mejor precisión (100%). Esto puede deberse a que el conjunto de prueba más grande (45 muestras) permite una mejor evaluación. La combinación específica de datos en el split con random_state=42 favoreció esta división. Con conjuntos de entrenamiento muy grandes (90/10), hay muy pocas muestras de prueba (15), lo que puede no ser representativo del comportamiento real del modelo.\n",
        "\n",
        "## 2. ¿Qué relación observas entre el tamaño del conjunto de entrenamiento y el tiempo de cómputo?\n",
        "\n",
        "Observación: El tiempo de entrenamiento se mantiene relativamente constante entre las diferentes divisiones.\n",
        "\n",
        "- 70/30: 0.2604 segundos\n",
        "- 80/20: 0.2333 segundos  \n",
        "- 90/10: 0.2570 segundos\n",
        "\n",
        "Análisis: Los tiempos son muy similares con diferencias mínimas. Esto ocurre porque el dataset Iris es muy pequeño (150 muestras totales), por lo que las diferencias en tamaño (105 vs 135 muestras) no son suficientes para afectar significativamente el tiempo de entrenamiento. En datasets más grandes si se observaría una relación más clara donde más datos implican mayor tiempo de procesamiento.\n",
        "\n",
        "## 3. ¿Cuál es la configuración que ofrece un mejor balance entre tiempo y precisión?\n",
        "\n",
        "Recomendación: División 70/30\n",
        "\n",
        "Justificación:\n",
        "\n",
        "La división 70/30 presenta la mejor precisión con 100% de accuracy, mientras que el tiempo de entrenamiento (0.2604 segundos) es prácticamente igual a las demás configuraciones. Además, esta división proporciona un conjunto de prueba más robusto con 45 muestras, lo que permite una evaluación más confiable del modelo. \n",
        "\n",
        "En general, la división 70/30 es una de las más utilizadas en Machine Learning porque ofrece un buen equilibrio entre tener suficientes datos para entrenar el modelo y mantener un conjunto de prueba representativo para validar su rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Punto 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diferentes configuraciones de capas ocultas y neuronas\n",
        "configuraciones = [\n",
        "    ((5, 5), '(5,5)'),\n",
        "    ((10, 10), '(10,10)'),\n",
        "    ((20, 20), '(20,20)')\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for hidden_layers, config_name in configuraciones:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"CONFIGURACIÓN: {config_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # División del dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "    \n",
        "    # Crear y entrenar el modelo\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    mlp = MLPClassifier(hidden_layer_sizes=hidden_layers, max_iter=1000, random_state=42, verbose=False)\n",
        "    mlp.fit(X_train, y_train)\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # Predicciones\n",
        "    y_pred = mlp.predict(X_test)\n",
        "    \n",
        "    # Métricas\n",
        "    accuracy = np.mean(y_test == y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    final_loss = mlp.loss_\n",
        "    \n",
        "    # Guardar resultados\n",
        "    results.append({\n",
        "        'config': config_name,\n",
        "        'accuracy': accuracy,\n",
        "        'conf_matrix': conf_matrix,\n",
        "        'training_time': training_time,\n",
        "        'final_loss': final_loss,\n",
        "        'n_iter': mlp.n_iter_\n",
        "    })\n",
        "    \n",
        "    # Imprimir resultados\n",
        "    print(f\"Capas ocultas: {hidden_layers}\")\n",
        "    print(f\"Tiempo de entrenamiento: {training_time:.4f} segundos\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Error final (loss): {final_loss:.6f}\")\n",
        "    print(f\"Número de iteraciones: {mlp.n_iter_}\")\n",
        "    print(f\"\\nMatriz de Confusión:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "# Comparación final\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"RESUMEN COMPARATIVO\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"{'Config':<10} {'Accuracy':<12} {'Loss':<12} {'Tiempo (s)':<12} {'Iteraciones'}\")\n",
        "print(\"-\" * 60)\n",
        "for r in results:\n",
        "    print(f\"{r['config']:<10} {r['accuracy']:<12.4f} {r['final_loss']:<12.6f} {r['training_time']:<12.4f} {r['n_iter']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ¿Cómo influye el número de capas ocultas y neuronas en la precisión del modelo?\n",
        "\n",
        "Observación: En este caso particular, el número de capas y neuronas no afectó la precisión final del modelo.\n",
        "\n",
        "- (5,5): Accuracy = 1.0000 (100%)\n",
        "- (10,10): Accuracy = 1.0000 (100%)\n",
        "- (20,20): Accuracy = 1.0000 (100%)\n",
        "\n",
        "Análisis: Las tres configuraciones alcanzaron una precisión perfecta del 100%. Esto sugiere que el dataset Iris es relativamente simple y no requiere arquitecturas complejas para clasificar correctamente las muestras. Incluso la configuración más pequeña (5,5) fue suficiente para aprender los patrones necesarios. Sin embargo, se observa una diferencia en el error final (loss), donde configuraciones con más neuronas tienden a tener un loss menor, indicando un mejor ajuste interno del modelo.\n",
        "\n",
        "## 2. ¿Qué configuración logra un mejor desempeño en términos de precisión y tiempo de cómputo?\n",
        "\n",
        "Recomendación: Configuración (10,10)\n",
        "\n",
        "Justificación:\n",
        "\n",
        "La configuración (10,10) ofrece el mejor balance entre precisión y eficiencia computacional. Aunque las tres configuraciones tienen la misma precisión (100%), esta presenta un tiempo de entrenamiento intermedio de 0.2413 segundos. La configuración (5,5) es ligeramente más lenta (0.3578 segundos) posiblemente porque necesitó más iteraciones (897) para converger. La configuración (20,20) es la más rápida (0.2340 segundos) pero utiliza más recursos y parámetros innecesariamente dado que no mejora la precisión.\n",
        "\n",
        "## 3. ¿Cuál es el impacto del incremento en las neuronas en el tiempo de entrenamiento?\n",
        "\n",
        "Observación: El incremento de neuronas no sigue una relación lineal directa con el tiempo de entrenamiento.\n",
        "\n",
        "- (5,5): 0.3578 segundos con 897 iteraciones\n",
        "- (10,10): 0.2413 segundos con 600 iteraciones\n",
        "- (20,20): 0.2340 segundos con 543 iteraciones\n",
        "\n",
        "Análisis: Contraintuitivamente, la configuración con menos neuronas (5,5) tomó más tiempo de entrenamiento. Esto se debe a que necesitó más iteraciones (897) para alcanzar la convergencia. Las redes más grandes (10,10) y (20,20) convergieron más rápido porque tienen mayor capacidad de aprendizaje, necesitando menos iteraciones (600 y 543 respectivamente). Sin embargo, cada iteración en una red más grande es computacionalmente más costosa. En datasets más complejos y grandes, se esperaría que redes con más neuronas tomen significativamente más tiempo debido al incremento en el número de parámetros a optimizar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Punto 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diferentes funciones de activación\n",
        "activaciones = ['relu', 'tanh', 'logistic']\n",
        "\n",
        "results = []\n",
        "\n",
        "for activation in activaciones:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"FUNCIÓN DE ACTIVACIÓN: {activation}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # División del dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "    \n",
        "    # Crear y entrenar el modelo\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10), activation=activation, max_iter=1000, random_state=42, verbose=False)\n",
        "    mlp.fit(X_train, y_train)\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # Predicciones\n",
        "    y_pred = mlp.predict(X_test)\n",
        "    \n",
        "    # Métricas\n",
        "    accuracy = np.mean(y_test == y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    final_loss = mlp.loss_\n",
        "    \n",
        "    # Guardar resultados\n",
        "    results.append({\n",
        "        'activation': activation,\n",
        "        'accuracy': accuracy,\n",
        "        'conf_matrix': conf_matrix,\n",
        "        'training_time': training_time,\n",
        "        'final_loss': final_loss,\n",
        "        'n_iter': mlp.n_iter_\n",
        "    })\n",
        "    \n",
        "    # Imprimir resultados\n",
        "    print(f\"Función de activación: {activation}\")\n",
        "    print(f\"Tiempo de entrenamiento: {training_time:.4f} segundos\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Error final (loss): {final_loss:.6f}\")\n",
        "    print(f\"Número de iteraciones: {mlp.n_iter_}\")\n",
        "    print(f\"\\nMatriz de Confusión:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "# Comparación final\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"RESUMEN COMPARATIVO\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"{'Activación':<12} {'Accuracy':<12} {'Loss':<12} {'Tiempo (s)':<12} {'Iteraciones'}\")\n",
        "print(\"-\" * 60)\n",
        "for r in results:\n",
        "    print(f\"{r['activation']:<12} {r['accuracy']:<12.4f} {r['final_loss']:<12.6f} {r['training_time']:<12.4f} {r['n_iter']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ¿Cómo afecta la elección de la función de activación a los resultados de precisión y matriz de confusión?\n",
        "\n",
        "Observación: La función de activación tiene un impacto significativo en la precisión del modelo.\n",
        "\n",
        "- relu: Accuracy = 1.0000 (100%)\n",
        "- tanh: Accuracy = 1.0000 (100%)\n",
        "- logistic: Accuracy = 0.9778 (97.78%)\n",
        "\n",
        "Análisis: Las funciones relu y tanh lograron clasificar correctamente todas las muestras del conjunto de prueba, obteniendo una precisión perfecta del 100%. Sin embargo, la función logistic tuvo un desempeño ligeramente inferior con 97.78% de precisión, lo que indica que cometió algunos errores de clasificación. Esto sugiere que para este dataset en particular, las funciones relu y tanh son más apropiadas para capturar los patrones de clasificación de las flores Iris. La función logistic, al tener un rango de salida más limitado (0 a 1), puede haber tenido dificultades para diferenciar ciertas clases.\n",
        "\n",
        "## 2. ¿Qué función de activación logra un mejor tiempo de convergencia?\n",
        "\n",
        "Recomendación: relu\n",
        "\n",
        "Justificación:\n",
        "\n",
        "La función relu presenta el mejor tiempo de convergencia con 0.2461 segundos y 600 iteraciones. La función tanh es ligeramente más lenta con 0.2792 segundos y 747 iteraciones. La función logistic es significativamente más lenta, necesitando 0.3799 segundos y 1000 iteraciones (el máximo permitido), lo que indica que no logró converger completamente dentro del límite establecido. La eficiencia de relu se debe a su simplicidad computacional y a que no sufre del problema de gradientes desvanecientes tan pronunciado como las otras funciones.\n",
        "\n",
        "## 3. ¿Qué diferencias observas en el comportamiento de la red para cada función de activación en términos de curva de aprendizaje?\n",
        "\n",
        "Observación: Las funciones presentan diferentes patrones de convergencia según el error final y número de iteraciones.\n",
        "\n",
        "- relu: Loss = 0.073790, 600 iteraciones (convergencia rápida y estable)\n",
        "- tanh: Loss = 0.076759, 747 iteraciones (convergencia moderada)\n",
        "- logistic: Loss = 0.149331, 1000 iteraciones (convergencia lenta, no completada)\n",
        "\n",
        "Análisis: La función relu muestra la curva de aprendizaje más eficiente, alcanzando el menor error en menos iteraciones, lo que indica una convergencia rápida y estable. La función tanh presenta un comportamiento similar pero requiere más iteraciones para estabilizarse. La función logistic muestra una curva de aprendizaje más lenta y problemática, necesitando el máximo de iteraciones permitidas sin lograr un error tan bajo como las otras funciones. Esto sugiere que logistic tiene más dificultades para optimizar los pesos de la red en este problema, posiblemente debido a que sus gradientes son más pequeños en los extremos, ralentizando el aprendi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Punto 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eliminar warnnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Configuraciones a probar\n",
        "splits = [(0.3, '70/30'), (0.2, '80/20'), (0.1, '90/10')]\n",
        "configuraciones = [((5, 5), '(5,5)'), ((10, 10), '(10,10)'), ((20, 20), '(20,20)')]\n",
        "activaciones = ['relu', 'tanh', 'logistic']\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"MIDIENDO TIEMPOS DE CÓMPUTO PARA TODAS LAS CONFIGURACIONES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Iterar sobre todas las combinaciones\n",
        "for test_size, split_name in splits:\n",
        "    for hidden_layers, config_name in configuraciones:\n",
        "        for activation in activaciones:\n",
        "            \n",
        "            # División del dataset\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=42)\n",
        "            \n",
        "            # Crear y entrenar el modelo\n",
        "            import time\n",
        "            start_time = time.time()\n",
        "            \n",
        "            mlp = MLPClassifier(hidden_layer_sizes=hidden_layers, activation=activation, max_iter=1000, random_state=42, verbose=False)\n",
        "            mlp.fit(X_train, y_train)\n",
        "            \n",
        "            training_time = time.time() - start_time\n",
        "            \n",
        "            # Predicciones\n",
        "            y_pred = mlp.predict(X_test)\n",
        "            \n",
        "            # Métricas\n",
        "            accuracy = np.mean(y_test == y_pred)\n",
        "            final_loss = mlp.loss_\n",
        "            \n",
        "            # Guardar resultados\n",
        "            results.append({\n",
        "                'split': split_name,\n",
        "                'config': config_name,\n",
        "                'activation': activation,\n",
        "                'accuracy': accuracy,\n",
        "                'training_time': training_time,\n",
        "                'final_loss': final_loss,\n",
        "                'n_iter': mlp.n_iter_,\n",
        "                'train_size': len(X_train),\n",
        "                'test_size': len(X_test)\n",
        "            })\n",
        "            \n",
        "            print(f\"Split: {split_name} | Config: {config_name} | Act: {activation:<8} | Time: {training_time:.4f}s | Acc: {accuracy:.4f}\")\n",
        "\n",
        "# Resumen por división de datos\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"RESUMEN POR DIVISIÓN DE DATOS\")\n",
        "print(f\"{'='*70}\")\n",
        "for split_name in ['70/30', '80/20', '90/10']:\n",
        "    split_results = [r for r in results if r['split'] == split_name]\n",
        "    avg_time = np.mean([r['training_time'] for r in split_results])\n",
        "    avg_acc = np.mean([r['accuracy'] for r in split_results])\n",
        "    print(f\"{split_name}: Tiempo promedio = {avg_time:.4f}s, Accuracy promedio = {avg_acc:.4f}\")\n",
        "\n",
        "# Resumen por configuración de neuronas\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"RESUMEN POR CONFIGURACIÓN DE NEURONAS\")\n",
        "print(f\"{'='*70}\")\n",
        "for config_name in ['(5,5)', '(10,10)', '(20,20)']:\n",
        "    config_results = [r for r in results if r['config'] == config_name]\n",
        "    avg_time = np.mean([r['training_time'] for r in config_results])\n",
        "    avg_acc = np.mean([r['accuracy'] for r in config_results])\n",
        "    print(f\"{config_name}: Tiempo promedio = {avg_time:.4f}s, Accuracy promedio = {avg_acc:.4f}\")\n",
        "\n",
        "# Resumen por función de activación\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"RESUMEN POR FUNCIÓN DE ACTIVACIÓN\")\n",
        "print(f\"{'='*70}\")\n",
        "for activation in ['relu', 'tanh', 'logistic']:\n",
        "    act_results = [r for r in results if r['activation'] == activation]\n",
        "    avg_time = np.mean([r['training_time'] for r in act_results])\n",
        "    avg_acc = np.mean([r['accuracy'] for r in act_results])\n",
        "    print(f\"{activation}: Tiempo promedio = {avg_time:.4f}s, Accuracy promedio = {avg_acc:.4f}\")\n",
        "\n",
        "# Configuración más rápida y más precisa\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ANÁLISIS DE CONFIGURACIONES EXTREMAS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "fastest = min(results, key=lambda x: x['training_time'])\n",
        "print(f\"\\nConfiguración MÁS RÁPIDA:\")\n",
        "print(f\"Split: {fastest['split']}, Config: {fastest['config']}, Activación: {fastest['activation']}\")\n",
        "print(f\"Tiempo: {fastest['training_time']:.4f}s, Accuracy: {fastest['accuracy']:.4f}\")\n",
        "\n",
        "most_accurate = max(results, key=lambda x: x['accuracy'])\n",
        "print(f\"\\nConfiguración MÁS PRECISA:\")\n",
        "print(f\"Split: {most_accurate['split']}, Config: {most_accurate['config']}, Activación: {most_accurate['activation']}\")\n",
        "print(f\"Tiempo: {most_accurate['training_time']:.4f}s, Accuracy: {most_accurate['accuracy']:.4f}\")\n",
        "\n",
        "# Mejor balance (accuracy >= 0.98 y menor tiempo)\n",
        "balanced = min([r for r in results if r['accuracy'] >= 0.98], key=lambda x: x['training_time'])\n",
        "print(f\"\\nMEJOR BALANCE (Accuracy >= 98% con menor tiempo):\")\n",
        "print(f\"Split: {balanced['split']}, Config: {balanced['config']}, Activación: {balanced['activation']}\")\n",
        "print(f\"Tiempo: {balanced['training_time']:.4f}s, Accuracy: {balanced['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Respuestas basadas en los resultados\n",
        "\n",
        "## 1. ¿Qué parámetros de la red tienen un mayor impacto en el tiempo de cómputo?\n",
        "\n",
        "Análisis por parámetro:\n",
        "\n",
        "División de datos:\n",
        "- 70/30: Tiempo promedio = 0.3033s\n",
        "- 80/20: Tiempo promedio = 0.3033s\n",
        "- 90/10: Tiempo promedio = 0.3033s\n",
        "\n",
        "Configuración de neuronas:\n",
        "- (5,5): Tiempo promedio = 0.3541s\n",
        "- (10,10): Tiempo promedio = 0.2686s\n",
        "- (20,20): Tiempo promedio = 0.2872s\n",
        "\n",
        "Función de activación:\n",
        "- relu: Tiempo promedio = 0.2646s\n",
        "- tanh: Tiempo promedio = 0.2651s\n",
        "- logistic: Tiempo promedio = 0.3803s\n",
        "\n",
        "Conclusión: La función de activación es el parámetro con mayor impacto en el tiempo de cómputo. La función logistic es significativamente más lenta (0.3803s) comparada con relu (0.2646s) y tanh (0.2651s). La configuración de neuronas también influye, donde redes muy pequeñas como (5,5) requieren más tiempo porque necesitan más iteraciones para converger. La división de datos tiene un impacto mínimo en el tiempo de entrenamiento debido al pequeño tamaño del dataset.\n",
        "\n",
        "## 2. ¿Cómo se puede mejorar el tiempo de ejecución sin perder demasiada precisión?\n",
        "\n",
        "Estrategias identificadas:\n",
        "\n",
        "Usar función de activación relu: Es la más rápida (0.2646s promedio) y mantiene alta precisión. Evitar logistic que es 44% más lenta.\n",
        "\n",
        "Configuración óptima de neuronas: Usar (10,10) o (20,20) en lugar de (5,5). Aunque parezca contraintuitivo, redes muy pequeñas necesitan más iteraciones. La configuración (10,10) ofrece el mejor tiempo (0.2686s) con excelente precisión.\n",
        "\n",
        "División de datos: Usar 70/30 o 80/20 proporciona suficientes datos de entrenamiento sin impacto significativo en tiempo.\n",
        "\n",
        "Ejemplo práctico: Cambiar de una configuración (5,5) con logistic (0.3597s) a (10,10) con relu (0.2323s) reduce el tiempo en 35% manteniendo 100% de precisión.\n",
        "\n",
        "## 3. ¿Cuál sería el mejor enfoque para lograr un balance entre precisión y tiempo de cómputo?\n",
        "\n",
        "Recomendación: Split 70/30, Config (10,10), Activación relu\n",
        "\n",
        "Justificación basada en resultados:\n",
        "\n",
        "Esta configuración logró:\n",
        "- Tiempo: 0.2323s (uno de los más rápidos)\n",
        "- Accuracy: 1.0000 (100% de precisión)\n",
        "- Iteraciones: Convergencia eficiente\n",
        "\n",
        "Comparación con otras configuraciones de 100% accuracy:\n",
        "- (20,20) con relu: 0.2270s (solo 0.0053s más rápido pero usa más recursos)\n",
        "- (10,10) con tanh: 0.2790s (0.0467s más lento)\n",
        "\n",
        "Enfoque general recomendado:\n",
        "\n",
        "1. Priorizar función de activación relu por su velocidad y efectividad\n",
        "2. Usar configuraciones intermedias de neuronas (10,10) que balanceen capacidad de aprendizaje y velocidad de convergencia\n",
        "3. Mantener división 70/30 para tener conjunto de prueba representativo\n",
        "4. Evitar configuraciones extremas: muy pequeñas (requieren más iteraciones) o muy grandes (innecesariamente complejas)\n",
        "\n",
        "Este enfoque garantiza tiempos de entrenamiento rápidos sin comprometer la precisión del modelo."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "etarea6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
